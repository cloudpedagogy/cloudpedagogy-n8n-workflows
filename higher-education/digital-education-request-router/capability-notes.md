# Capability Notes — Digital Education Request Router (HE-03)

These notes explain how the **Digital Education Request Router** demonstrates applied AI capability in practice, using the CloudPedagogy AI Capability Framework as a guiding lens.

They are intended to support reflective use, adaptation, and responsible scaling — not to prescribe a single “correct” implementation.

---

## Purpose of this workflow from a capability perspective

Digital education teams operate in environments characterised by:
- high volumes of unstructured requests
- competing priorities and time pressures
- ambiguity around urgency and ownership
- limited shared visibility across teams

This workflow addresses these challenges by using AI to **support sense-making and coordination**, while keeping judgement, accountability, and decision authority with people.

The primary capability being exercised is **triage under uncertainty**, not automation of outcomes.

---

## How AI is used (and how it is not)

### What AI supports
AI is used to assist with:
- identifying the likely category of a request
- suggesting urgency based on language and context
- producing short summaries to aid human understanding

These uses reduce cognitive load and improve consistency in early-stage triage.

### What AI does not do
AI does **not**:
- approve or reject requests
- assign responsibility definitively
- determine priorities without human review
- close or resolve issues automatically

All downstream action remains subject to human judgement.

---

## Human–AI co-agency in practice

This workflow is designed to make the human–AI relationship explicit:

- AI outputs are framed as **suggestions**, not conclusions
- confidence scores or uncertainty thresholds can be used to trigger manual triage
- ambiguous or low-confidence cases are routed for human review
- teams remain free to override, ignore, or reinterpret AI classifications

This supports appropriate reliance rather than automation bias.

---

## Capability domain alignment

### AI Awareness & Orientation
Users are expected to understand:
- that AI classifications are probabilistic
- that outputs may reflect bias or uncertainty
- that language cues can be misinterpreted

The workflow encourages critical engagement rather than blind trust.

---

### Human–AI Co-Agency
Roles are clearly separated:
- AI assists with initial sense-making
- humans decide what happens next

Responsibility for decisions remains explicit and attributable.

---

### Applied Practice & Innovation
The workflow focuses on a **real, everyday problem** rather than abstract AI use:
- inbox overload
- unclear requests
- coordination across roles

It demonstrates how AI can be embedded into existing work without requiring wholesale process redesign.

---

### Ethics, Equity & Impact
Design choices prioritise:
- data minimisation (logging metadata rather than full content where possible)
- transparency of routing logic
- avoidance of hidden or irreversible decisions

Teams should reflect on whether certain request types or language patterns may be disadvantaged by automated classification and adjust accordingly.

---

### Decision-Making & Governance
Routing decisions are:
- explicit
- inspectable
- logged for later review

This supports accountability, defensibility, and institutional learning — particularly in regulated or high-stakes environments.

---

### Reflection, Learning & Renewal
By logging classifications and outcomes, teams can:
- review patterns over time
- identify recurring issues or bottlenecks
- adjust categories, thresholds, or processes
- reflect on where AI assistance is helpful or misleading

The workflow supports **continuous improvement**, not one-off optimisation.

---

## Appropriate use contexts

This workflow is well suited to:
- individual learning technologists
- small digital education teams
- faculty-level support services
- early-stage institutional pilots

It may require additional governance or adaptation when used:
- at scale across large institutions
- in high-risk or compliance-sensitive contexts
- where requests involve sensitive personal data

---

## When not to use this workflow

This workflow may not be appropriate when:
- requests require immediate human judgement without mediation
- full content logging would create unacceptable privacy risks
- deterministic rules are more suitable than AI-assisted classification

In such cases, simpler or more manual processes may be preferable.

---

## Relationship to the AI Capability Framework

This workflow should be understood as **one operational expression** of the CloudPedagogy AI Capability Framework.

It does not replace:
- policy
- training
- governance processes
- professional judgement

Instead, it demonstrates how capability principles can be enacted through everyday tools and workflows, in a way that remains adaptable, transparent, and human-centred.
